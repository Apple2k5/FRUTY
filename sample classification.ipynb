{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9fd4680-8381-4ac9-9b8a-e9ab20b1911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Setting up Data Generators...\n",
      "Found 8000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Detected 10 Classes: ['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
      "Total Training Images: 8000\n",
      "Total Validation Images: 2000\n",
      "\n",
      "2. Starting Model Training (5 Epochs)...\n",
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.2626 - loss: 2.1345 - val_accuracy: 0.6170 - val_loss: 1.0704\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.5887 - loss: 1.1943 - val_accuracy: 0.7465 - val_loss: 0.7724\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 1s/step - accuracy: 0.6666 - loss: 0.9800 - val_accuracy: 0.7970 - val_loss: 0.6501\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 1s/step - accuracy: 0.7125 - loss: 0.8193 - val_accuracy: 0.8005 - val_loss: 0.5824\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.7448 - loss: 0.7370 - val_accuracy: 0.8405 - val_loss: 0.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Complete. Model saved as 'tomato_disease_classifier.h5'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "import random\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# üö® IMPORTANT: Replace this placeholder with the ACTUAL PATH to your dataset's 'train' folder.\n",
    "# This folder must contain the class subdirectories (e.g., Tomato___Healthy, Tomato___Late_blight, etc.)\n",
    "DATA_DIR = 'tomato/train'  \n",
    "MODEL_FILE_NAME = 'tomato_disease_classifier.h5'\n",
    "\n",
    "IMAGE_SIZE = (128, 128)  # Standard input size for the CNN\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- STEP 1: DATA PREPARATION (Keras Generators) ---\n",
    "\n",
    "print(\"1. Setting up Data Generators...\")\n",
    "\n",
    "# Initialize the generator with normalization and data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,             # Normalize pixel values (0 to 1)\n",
    "    validation_split=0.2,       # Use 20% of data for validation\n",
    "\n",
    "    # Data Augmentation (Crucial for better model generalization)\n",
    "    rotation_range=20,          \n",
    "    horizontal_flip=True,       \n",
    "    zoom_range=0.1              \n",
    ")\n",
    "\n",
    "# Training Data Generator: Loads the training subset\n",
    "try:\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        DATA_DIR,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Validation Data Generator: Loads the validation subset\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        DATA_DIR,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "    NUM_CLASSES = len(class_names)\n",
    "\n",
    "    if train_generator.n == 0:\n",
    "         raise ValueError(f\"Found 0 images in the training subset. Please verify the DATA_DIR path: {DATA_DIR}\")\n",
    "    \n",
    "    print(f\"Detected {NUM_CLASSES} Classes: {class_names}\")\n",
    "    print(f\"Total Training Images: {train_generator.n}\")\n",
    "    print(f\"Total Validation Images: {validation_generator.n}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- FATAL ERROR IN DATA LOADING ---\")\n",
    "    print(\"Check the folder structure and path again. Details:\")\n",
    "    print(e)\n",
    "    exit() \n",
    "\n",
    "# --- STEP 2: BUILD AND TRAIN THE CNN MODEL ---\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"Creates a simple Convolutional Neural Network model.\"\"\"\n",
    "    model = Sequential([\n",
    "        # Feature Extraction Layers\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Classification Head\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5), # Regularization\n",
    "        Dense(num_classes, activation='softmax') # Output layer\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_cnn_model(IMAGE_SIZE + (3,), NUM_CLASSES)\n",
    "\n",
    "print(\"\\n2. Starting Model Training (5 Epochs)...\")\n",
    "# Note: You can increase the number of epochs for better accuracy if you have time.\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5, \n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Complete. Model saved as '{MODEL_FILE_NAME}'\")\n",
    "model.save(MODEL_FILE_NAME)\n",
    "\n",
    "# --- STEP 3: PREDICTION FUNCTION ---\n",
    "\n",
    "def predict_leaf_disease(image_path, model, class_names, target_size):\n",
    "    \"\"\"Predicts the disease class of a new image.\"\"\"\n",
    "    \n",
    "    # 1. Load and Preprocess using OpenCV\n",
    "    img_cv = cv2.imread(image_path)\n",
    "    if img_cv is None:\n",
    "        return f\"ERROR: Image not found at {image_path}.\", None\n",
    "        \n",
    "    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB) # Convert BGR (OpenCV default) to RGB\n",
    "    img_resized = cv2.resize(img_rgb, target_size)\n",
    "    \n",
    "    img_array = np.array(img_resized) / 255.0  # Normalize to 0-1\n",
    "    img_array = np.expand_dims(img_array, axis=0) # Add batch dimension\n",
    "\n",
    "    # 2. Predict\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    \n",
    "    # 3. Interpret Result\n",
    "    predicted_class_index = np.argmax(score)\n",
    "    confidence = np.max(score) * 100\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    \n",
    "    result = (\n",
    "        f\"Prediction: **{predicted_class.replace('___', ' ')}**\\n\"\n",
    "        f\"Confidence: {confidence:.2f}%\"\n",
    "    )\n",
    "    \n",
    "    return result, score\n",
    "\n",
    "# --- Example Prediction (Optional: Uncomment to test) ---\n",
    "# # To test: Get a path to any image in one of your class folders and paste it here.\n",
    "# # test_image_path = '/path/to/your/Kaggle/Tomato_leaf_disease_detection/train/Tomato___Healthy/0001.jpg'\n",
    "# \n",
    "# # try:\n",
    "# #     prediction_result, scores = predict_leaf_disease(test_image_path, model, class_names, IMAGE_SIZE)\n",
    "# #     print(f\"\\n--- SAMPLE PREDICTION ---\\n{prediction_result}\")\n",
    "# # except NameError:\n",
    "# #     print(\"Prediction failed. Ensure 'test_image_path' is defined and the model has finished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f006daba-456b-4edd-ad11-a07af03c027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "\n",
      "--- SAMPLE PREDICTION ---\n",
      "Prediction: **Tomato Tomato_Yellow_Leaf_Curl_Virus**\n",
      "Confidence: 23.11%\n"
     ]
    }
   ],
   "source": [
    "test_image_path = 'tomato/train/Tomato___Tomato_Yellow_Leaf_Curl_Virus/d01c276a-a70d-4981-930e-d78292219f61___UF.GRC_YLCV_Lab 02057.JPG'\n",
    "try:\n",
    "    prediction_result, scores = predict_leaf_disease(test_image_path, model, class_names, IMAGE_SIZE)\n",
    "    print(f\"\\n--- SAMPLE PREDICTION ---\\n{prediction_result}\")\n",
    "except NameError:\n",
    "    print(\"Prediction failed. Ensure 'test_image_path' is defined and the model has finished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e812871a-e187-44a3-aba2-5d1da5b9e792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: tomato_disease_classifier.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LIVE CLASSIFIER READY ---\n",
      "Press 'c' to Capture and Classify the current frame.\n",
      "Press 'q' to Quit.\n",
      "\n",
      "[INFO] Capturing and classifying...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step\n",
      "   -> Result: Tomato Early_blight (20.73%)\n",
      "   -> Guidance: üßê TREAT. Moderate disease, requires treatment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_FILE_NAME = 'tomato_disease_classifier.h5' \n",
    "IMAGE_SIZE = (128, 128) # Must match the size used during training\n",
    "\n",
    "# --- STEP 1: LOAD MODEL AND CLASS NAMES ---\n",
    "\n",
    "try:\n",
    "    print(f\"Loading model from: {MODEL_FILE_NAME}...\")\n",
    "    model = load_model(MODEL_FILE_NAME)\n",
    "\n",
    "    # üö® IMPORTANT: Define class names in the EXACT order they were learned by the generator.\n",
    "    # If you trained on the original Kaggle dataset, use this list (or the list saved during training).\n",
    "    class_names = [\n",
    "        'Tomato___Bacterial_spot', \n",
    "        'Tomato___Early_blight',\n",
    "        'Tomato___Healthy',\n",
    "        'Tomato___Late_blight',\n",
    "        'Tomato___Leaf_Mold',\n",
    "        'Tomato___Septoria_leaf_spot',\n",
    "        'Tomato___Spider_mites Two-spotted_spider_mite',\n",
    "        'Tomato___Target_Spot',\n",
    "        'Tomato___Tomato_mosaic_virus',\n",
    "        'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
    "    ]\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n--- ERROR: Model Not Found ---\")\n",
    "    print(f\"Please ensure '{MODEL_FILE_NAME}' is in the current directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ERROR: Could not load model or classes ---\")\n",
    "    print(f\"Details: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- STEP 2: CLASSIFICATION FUNCTION (Modified to accept a frame) ---\n",
    "\n",
    "def classify_frame(frame, model, class_names, target_size):\n",
    "    \"\"\"Preprocesses a captured frame and makes a prediction.\"\"\"\n",
    "    \n",
    "    # 1. Preprocessing\n",
    "    # Convert BGR (OpenCV frame default) to RGB \n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "    \n",
    "    # Resize to the model's required input size\n",
    "    img_resized = cv2.resize(img_rgb, target_size)\n",
    "    \n",
    "    # Convert to NumPy array and normalize (0-1)\n",
    "    img_array = np.array(img_resized) / 255.0  \n",
    "    \n",
    "    # Add a batch dimension: (1, 128, 128, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0) \n",
    "\n",
    "    # 2. Make Prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    probabilities = tf.nn.softmax(predictions[0]) \n",
    "    \n",
    "    # Get the result\n",
    "    predicted_index = np.argmax(probabilities)\n",
    "    confidence = np.max(probabilities) * 100\n",
    "    predicted_class = class_names[predicted_index]\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# --- STEP 3: CAMERA CAPTURE LOOP ---\n",
    "\n",
    "def run_live_classifier():\n",
    "    # Initialize webcam (0 is usually the default camera)\n",
    "    cap = cv2.VideoCapture(0) \n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"\\n--- ERROR ---: Cannot open camera. Check camera index or connection.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- LIVE CLASSIFIER READY ---\")\n",
    "    print(\"Press 'c' to Capture and Classify the current frame.\")\n",
    "    print(\"Press 'q' to Quit.\")\n",
    "\n",
    "    # Variables for displaying the last result\n",
    "    last_prediction = \"Awaiting Capture...\"\n",
    "    last_confidence = 0.0\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        # Display the prediction text on the live feed\n",
    "        display_frame = frame.copy()\n",
    "        text = f\"Condition: {last_prediction} | Conf: {last_confidence:.2f}%\"\n",
    "        cv2.putText(display_frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(display_frame, \"Press 'c' to CAPTURE\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Tomato Leaf Live Classifier', display_frame)\n",
    "\n",
    "        # Handle key presses\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        \n",
    "        elif key == ord('c'):\n",
    "            print(\"\\n[INFO] Capturing and classifying...\")\n",
    "            \n",
    "            # Run the prediction\n",
    "            predicted_class, confidence = classify_frame(frame, model, class_names, IMAGE_SIZE)\n",
    "            \n",
    "            # Update the displayed text variables\n",
    "            last_prediction = predicted_class.replace('___', ' ')\n",
    "            last_confidence = confidence\n",
    "\n",
    "            # Log the result\n",
    "            print(f\"   -> Result: {last_prediction} ({confidence:.2f}%)\")\n",
    "            \n",
    "            # Provide actionable guidance based on the result\n",
    "            if \"Healthy\" in last_prediction:\n",
    "                print(\"   -> Guidance: üå± KEEP. Plant is healthy.\")\n",
    "            elif \"Virus\" in last_prediction or \"Late_blight\" in last_prediction:\n",
    "                print(\"   -> Guidance: ‚ö†Ô∏è REMOVE. Severe and highly contagious disease.\")\n",
    "            else:\n",
    "                print(\"   -> Guidance: üßê TREAT. Moderate disease, requires treatment.\")\n",
    "            \n",
    "            # Brief pause to visually emphasize the capture\n",
    "            time.sleep(0.5) \n",
    "\n",
    "    # When everything is done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Execute the live classifier\n",
    "run_live_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dc084-fffb-4c91-91c1-ac1028da5d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25d43b-d2c3-41b0-b859-d4984f2ba286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
